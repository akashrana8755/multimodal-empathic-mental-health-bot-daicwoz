# ğŸ§  EmpaCare: A Multimodal Empathetic Mental Health Chatbot

EmpaCare is a GenAI-powered mental health chatbot that uses multimodal signals (text and audio) to detect user emotion and depression severity (PHQ-8), and responds with contextually supportive and empathetic dialogue. Built on top of DAIC-WOZ dataset, the system combines LLaMA-3 + LoRA for response generation, LangChain + FAISS for RAG, and BERT + OpenSMILE for emotion detection.

---

## ğŸ§ª Key Features

- ğŸ™ï¸ Multimodal Emotion & Depression Detection (Text + Audio)
- ğŸ¤— Empathetic Response Generation using LLaMA-3 fine-tuned with LoRA
- ğŸ§  Context-Aware Dialogue via LangChain + FAISS (RAG)
- ğŸ©º Personalized support aligned with CBT principles
- ğŸŒ Gradio-based Web UI for demo and deployment

---

## ğŸ“¦ Dataset

**DAIC-WOZ**  
- Mental health interview corpus (text transcripts, audio features, visual features, PHQ-8 scores)  
- Download: [https://dcapswoz.ict.usc.edu/](https://dcapswoz.ict.usc.edu/)

---

## ğŸ”§ Tech Stack

| Component | Tools Used |
|----------|-------------|
| Language Model | LLaMA-3 + LoRA |
| Emotion Detection | BERT, OpenSMILE |
| Dialogue Manager | LangChain, FAISS |
| UI | Gradio |
| Frameworks | PyTorch, HuggingFace Transformers |
| Evaluation | RMSE, F1, Empathy Score, Human Eval |

---

## ğŸ§± System Architecture


+-----------------------------+
|    User Input (Text/Audio) |
+-----------------------------+
             â†“
+-----------------------------+
|   Multimodal Emotion Model  | â† BERT + OpenSMILE
+-----------------------------+
             â†“
+-----------------------------+
|  Emotion/PHQ Classifier     | â† MLP
+-----------------------------+
             â†“
+-----------------------------+
| Dialogue Manager (RAG)      | â† LangChain + FAISS
+-----------------------------+
             â†“
+-----------------------------+
| LLaMA-3 + LoRA (Empathetic) |
+-----------------------------+
             â†“
|     Contextual Response     |
+-----------------------------+


â¸»

ğŸš€ Getting Started

1. Clone the Repository

git clone https://github.com/your-username/EmpaCare.git
cd EmpaCare

2. Install Dependencies

pip install -r requirements.txt

3. Prepare DAIC-WOZ Data

Download the dataset and organize as follows:

data/
â”œâ”€â”€ daic_woz_transcripts/
â”œâ”€â”€ audio/
â””â”€â”€ phq_scores.csv

4. Extract Features

python preprocessing/text_preprocess.py
python preprocessing/audio_feature_extractor.py

5. Train Emotion & PHQ Classifier

python models/train_classifier.py

6. Fine-Tune LLaMA-3 with LoRA

python models/lora_finetune.py --base_model llama-3 --dataset EmpatheticDialogues

7. Launch the Chatbot

python app/gradio_ui.py


â¸»

ğŸ“Š Evaluation
	â€¢	PHQ-8 Score Prediction: RMSE, MAE
	â€¢	Emotion Detection: F1-Score (macro/weighted)
	â€¢	Response Quality: BLEU, ROUGE
	â€¢	Empathy: Comparison with EmpatheticDialogues + Human Ratings

â¸»

ğŸ“š Key References
	1.	Majumder et al. (2019) â€“ Multimodal Transformer for Emotion Recognition
	2.	Rashkin et al. (2019) â€“ EmpatheticDialogues Dataset
	3.	Liu et al. (2023) â€“ Mixtral and MixMoE LLMs
	4.	Althoff et al. (2016) â€“ Counseling Conversations for Mental Health
	5.	Stas et al. (2023) â€“ Parameter-Efficient LoRA Fine-Tuning

â¸»

ğŸ§‘â€ğŸ’» Contributing

We welcome community contributions! If youâ€™d like to:
	â€¢	Improve emotion modeling
	â€¢	Add visual modality
	â€¢	Tune response generation
	â€¢	Enhance evaluation

Please open an issue or submit a pull request.

â¸»

ğŸ“„ License

MIT License â€” feel free to use, modify, and share!

â¸»

ğŸ’¬ Acknowledgements

Thanks to the USC DAIC-WOZ team, HuggingFace community, LangChain developers, and researchers in affective computing for making this work possible.
----
